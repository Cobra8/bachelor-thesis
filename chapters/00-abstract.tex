% !TEX root = ../main.tex
Recently several works proposed new approaches on how advancements in machine learning can be used to improve indexing algorithms on sorted data. This resulted in the SOSD benchmark \cite{sosd-vldb} which enabled a baseline for evaluating different competitors in a standardized way. At the same time, with a wider adoption of network programmability through P4 \cite{p4-spec}, a trend towards outsourcing certain computationally intensive procedures to programmable switches started. Our goal is to combine these two advancements by maintaining recent progress that learned indexing algorithms offer and evaluating possibilities of even further leveraging their performance by using the power of network programmability.\\

After careful evaluation we come to the descision that we continue our work focussing on the learned indexing algorithm RMI \cite{rmi} which suits our idea of implementing parts of it over the network best. Indeed we find that the P4 specification \cite{p4-spec} allows an implementation of the lookup part of RMI on the switch and reaches perfect accuracy in doing so when testing on virtually simulated network hardware. At this point we analyze how far our theoretical implementation is from actually running on real world hardware and it will turn out that there is a long way to go. From this theoretical result we then generalize our solution to any dataset and arbitrary RMI configuration by adapting the code generation part of the RMI reference implementation \cite{cdfshop}. We finally conclude our work by coming up with a strategy to, even though having a theoretical implementation, estimate how much our idea of outsourcing RMI calculations to the network could benefit a system and find that we could save around 50-100ns per lookup per last mile search worker, which results in a constant speed up that scales horizontally with the amount of last mile search workers available to a single switch.
